{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405c5a93",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123d21b",
   "metadata": {},
   "source": [
    "# Tool usage test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2a3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I love drinking green tea in the afternoon.\n",
      "Output: ('i', 'like_food', 'green tea')\n",
      "Subject: i, Relation: like_food, Object: green tea\n"
     ]
    }
   ],
   "source": [
    "# Test PersonaExtractor tool directly\n",
    "from src.backend.tools.persona_extractor import persona_extractor\n",
    "\n",
    "# Test with sample input\n",
    "test_sentence = \"I love drinking green tea in the afternoon.\"\n",
    "result = persona_extractor.invoke({\"sentence\": test_sentence})\n",
    "\n",
    "print(f\"Input: {test_sentence}\")\n",
    "print(f\"Output: {result}\")\n",
    "print(f\"Subject: {result[0]}, Relation: {result[1]}, Object: {result[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ee799",
   "metadata": {},
   "source": [
    "# Agent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19050465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenizer already exists at: Tokenizers/phi-4-mini-instruct\n",
      "✅ Model already exists at: LLMs/phi-4-mini-instruct\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "# Define model ID and local paths\n",
    "model_id = \"microsoft/Phi-4-mini-instruct\"\n",
    "model_folder = \"LLMs/phi-4-mini-instruct\"\n",
    "tokenizer_folder = \"Tokenizers/phi-4-mini-instruct\"\n",
    "\n",
    "# Function to check if directory is already populated\n",
    "def is_downloaded(directory):\n",
    "    return os.path.exists(directory) and any(os.scandir(directory))\n",
    "\n",
    "# Create folders if necessary\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "os.makedirs(tokenizer_folder, exist_ok=True)\n",
    "\n",
    "# Download tokenizer if not already present\n",
    "if not is_downloaded(tokenizer_folder):\n",
    "    print(\"⬇️ Downloading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    tokenizer.save_pretrained(tokenizer_folder)\n",
    "    print(f\"✅ Tokenizer saved to: {tokenizer_folder}\")\n",
    "else:\n",
    "    print(f\"✅ Tokenizer already exists at: {tokenizer_folder}\")\n",
    "\n",
    "# Download model if not already present\n",
    "if not is_downloaded(model_folder):\n",
    "    print(\"⬇️ Downloading model...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True)\n",
    "    model.save_pretrained(model_folder)\n",
    "    print(f\"✅ Model saved to: {model_folder}\")\n",
    "else:\n",
    "    print(f\"✅ Model already exists at: {model_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb97e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c495a4b3c83441478137b88ec051d7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.backend.agents.agent import PersoAgent\n",
    "\n",
    "agent = PersoAgent(\n",
    "    model_path=\"LLMs/phi-4-mini-instruct\",\n",
    "    tokenizer_path=\"Tokenizers/phi-4-mini-instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b12e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I will use the Persona Extractor tool to extract the subject, relation, and object from the user's sentence.\n",
      "Tool: Persona Extractor\n",
      "Sentence: I love drinking green tea in the afternoon.\n",
      "Action: Persona Extractor\n",
      "Final Answer: The extracted triplet is (I, love, drinking green tea in the afternoon). That's nice! I learned that you enjoy drinking green tea in the afternoon. It's a great afternoon drink.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The extracted triplet is (I, love, drinking green tea in the afternoon). That's nice! I learned that you enjoy drinking green tea in the afternoon. It's a great afternoon drink.\n"
     ]
    }
   ],
   "source": [
    "# Simple invocation - just pass the task\n",
    "response = agent.handle_task(\"I love drinking green tea in the afternoon.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445cbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persoagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
