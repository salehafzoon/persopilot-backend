{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "405c5a93",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123d21b",
   "metadata": {},
   "source": [
    "# Tool usage test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b56b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Add console handler only if not already present\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27c39b",
   "metadata": {},
   "source": [
    "Persona Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2a3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "INFO:persona_util:SQLitePersonaDB initialized\n",
      "INFO:src.tools.persona_extractor_gpt:[START] DialogGPT extract() called with: I also like to eat pasta for dinner.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "INFO:src.tools.persona_extractor_gpt:[EXTRACTED] relation='favorite_food', object='also pasta', topic='Skill', task='Lifestyle Optimization'\n",
      "INFO:persona_util:Persona fact inserted for user user_91, task Lifestyle Optimization\n",
      "INFO:src.tools.persona_extractor_gpt:[SAVED TO DB] for username='user_91'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXTRACTED] relation='favorite_food', object='also pasta', topic='Skill', task='Lifestyle Optimization'\n"
     ]
    }
   ],
   "source": [
    "from src.tools.persona_extractor_gpt import get_dialogpt_persona_extractor_tool\n",
    "\n",
    "tool1 = get_dialogpt_persona_extractor_tool('user_91', 'Lifestyle Optimization')\n",
    "\n",
    "result1 = tool1.invoke({\"sentence\": \"I also like to eat pasta for dinner.\"})\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d1fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "INFO:persona_util:SQLitePersonaDB initialized\n",
      "INFO:src.tools.persona_extractor:[EXTRACTED] relation='favorite_food', object='pasta', topic='Skill', task='Lifestyle Optimization'\n",
      "INFO:persona_util:Persona fact inserted for user user_91, task Lifestyle Optimization\n",
      "INFO:src.tools.persona_extractor:[SAVED TO DB] for username='user_91'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXTRACTED] relation='favorite_food', object='pasta', topic='Skill', task='Lifestyle Optimization'\n"
     ]
    }
   ],
   "source": [
    "from src.tools.persona_extractor import get_persona_extractor_tool\n",
    "\n",
    "tool1 = get_persona_extractor_tool('user_91', 'Lifestyle Optimization')\n",
    "\n",
    "result1 = tool1.invoke({\"sentence\": \"I also like to eat pasta for dinner.\"})\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d0334e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.tools.persona_extractor:[EXTRACTED] relation='has_profession', object='scientist', topic='Career', task='Lifestyle Optimization'\n",
      "INFO:persona_util:Persona fact inserted for user user_91, task Lifestyle Optimization\n",
      "INFO:src.tools.persona_extractor:[SAVED TO DB] for username='user_91'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EXTRACTED] relation='has_profession', object='scientist', topic='Career', task='Lifestyle Optimization'\n"
     ]
    }
   ],
   "source": [
    "result2 = tool1.invoke({\"sentence\": \"I like to work as a data scientist.\"})\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d6be9",
   "metadata": {},
   "source": [
    "Community-based Recommender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e03480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - SQLitePersonaDB initialized\n",
      "INFO - [TOOL INVOKED] Community recommender triggered with input: Can you provide community recommendations?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TOOL RESULT]\n",
      "Type: Recommendation:\n",
      "Community suggestions for Content Consumption (from other users):\n",
      "- Book:\n",
      "  . occasionally reads news articles: liked by 10 users\n",
      "  . reading graphic novels: liked by 5 users\n",
      "  . reading science fiction: liked by 5 users\n",
      "- Game:\n",
      "  . card games: liked by 6 users\n",
      "  . strategy games: liked by 6 users\n",
      "  . arcade games: liked by 5 users\n",
      "- Movie:\n",
      "  . watching animated movies: liked by 6 users\n",
      "  . watching fantasy movies: liked by 6 users\n",
      "  . watching historical dramas: liked by 6 users\n",
      "- Music:\n",
      "  . hip hop music: liked by 6 users\n",
      "  . indie music: liked by 6 users\n",
      "  . reggae music: liked by 6 users\n"
     ]
    }
   ],
   "source": [
    "from src.tools.community_recommender import create_community_recommender_tool\n",
    "\n",
    "tool2 = create_community_recommender_tool(username=\"user_41\", task=\"Content Consumption\")\n",
    "\n",
    "result2 = tool2.invoke({\"sentence\": \"Can you provide community recommendations?\"})\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ee799",
   "metadata": {},
   "source": [
    "# Agent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96469ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548ffc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM = \"DialoGPT-small\"             # \"Phi-3.5-mini-instruct\", \"DialoGPT-small\"\n",
    "# model_id = f\"microsoft/{LLM}\"           # f\"meta-llama/{LLM}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304405e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# import os\n",
    "\n",
    "# # Define model ID and local paths\n",
    "\n",
    "# MODEL_PATH = f\"LLMs/{LLM}\"\n",
    "# TOKENIZER_PATH = f\"Tokenizers/{LLM}\"\n",
    "\n",
    "# # Function to check if directory is already populated\n",
    "# def is_downloaded(directory):\n",
    "#     return os.path.exists(directory) and any(os.scandir(directory))\n",
    "\n",
    "# # Create folders if necessary\n",
    "# os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "# os.makedirs(TOKENIZER_PATH, exist_ok=True)\n",
    "\n",
    "# # Download tokenizer if not already present\n",
    "# if not is_downloaded(TOKENIZER_PATH):\n",
    "#     print(\"⬇️ Downloading tokenizer...\")\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "#     tokenizer.save_pretrained(TOKENIZER_PATH)\n",
    "#     print(f\"✅ Tokenizer saved to: {TOKENIZER_PATH}\")\n",
    "# else:\n",
    "#     print(f\"✅ Tokenizer already exists at: {TOKENIZER_PATH}\")\n",
    "\n",
    "# # Download model if not already present\n",
    "# if not is_downloaded(MODEL_PATH):\n",
    "#     print(\"⬇️ Downloading model...\")\n",
    "#     model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True)\n",
    "#     model.save_pretrained(MODEL_PATH)\n",
    "#     print(f\"✅ Model saved to: {MODEL_PATH}\")\n",
    "# else:\n",
    "#     print(f\"✅ Model already exists at: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7118de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Add console handler\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7dbeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f97b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - SQLitePersonaDB initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Consumption\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'User user_02 preferences for Content Consumption: | Book: like_read 1984, 1984, 1984; likes reading biographies | Career: like_read 1984, 1984 | Game: plays board games | Movie: likes watching comedies | Music: likes pop music'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.persona_util import SQLitePersonaDB\n",
    "db = SQLitePersonaDB()\n",
    "\n",
    "USERNAME = \"user_02\"\n",
    "\n",
    "# db.create_user(USERNAME, 'Sali A', 28, 'male', 'user')\n",
    "\n",
    "USER = db.get_user(USERNAME)\n",
    "\n",
    "task_list = [f\"{task['name']}\" for task in db.get_all_tasks()]\n",
    "\n",
    "TASK = task_list[0]\n",
    "print(TASK)\n",
    "\n",
    "USER_PERSONA = db.get_user_persona_summary_by_task(USERNAME, TASK)\n",
    "# USER_PERSONA = USER_PERSONA.replace('user_01', USERNAME)\n",
    "\n",
    "USER_PERSONA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf8384",
   "metadata": {},
   "source": [
    "## OpenAI Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb97e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Initializing PersoAgent for user: user_02 with task: Content Consumption and previous personas: User user_02 preferences for Content Consumption: | Book: like_read 1984, 1984, 1984; likes reading biographies | Career: like_read 1984, 1984 | Game: plays board games | Movie: likes watching comedies | Music: likes pop music\n",
      "INFO - Initializing PersoAgent for user: {'username': 'user_02', 'full_name': 'Bob Johnson', 'age': 32, 'gender': 'male', 'role': 'user'} with task: Content Consumption\n",
      "Device set to use cuda:0\n",
      "INFO - SQLitePersonaDB initialized\n",
      "INFO - SQLitePersonaDB initialized\n"
     ]
    }
   ],
   "source": [
    "from src.agents.PersoAgent import PersoAgent\n",
    "\n",
    "agent = PersoAgent(\n",
    "    user = USER,\n",
    "    task = TASK,\n",
    "    prev_personas = USER_PERSONA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c740ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `PersonaExtractor` with `{'sentence': 'I just finished reading the 1984 book, and I loved it.'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - [EXTRACTED] relation='like_read', object='1984', topic='Book', task='Content Consumption'\n",
      "INFO - Persona fact inserted for user user_02, task Content Consumption\n",
      "INFO - [SAVED TO DB] for username='user_02'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[TOOL RESULT] relation='like_read', object='1984', topic='Book', task='Content Consumption'\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"response\": \"It's great to hear that you loved reading the book 1984!\",\n",
      "    \"reason\": \"User expressing his preference for the book 1984\",\n",
      "    \"used_tool\": \"PersonaExtractor\"\n",
      "}\n",
      "{\n",
      "    \"response\": \"It's great to hear that you loved reading the book 1984!\",\n",
      "    \"reason\": \"User expressing his preference for the book 1984\",\n",
      "    \"used_tool\": \"PersonaExtractor\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"response\": \"It's great to hear that you loved reading the book 1984!\",\n",
      "    \"reason\": \"User expressing his preference for the book 1984\",\n",
      "    \"used_tool\": \"PersonaExtractor\"\n",
      "}\n",
      "{\n",
      "    \"response\": \"It's great to hear that you loved reading the book 1984!\",\n",
      "    \"reason\": \"User expressing his preference for the book 1984\",\n",
      "    \"used_tool\": \"PersonaExtractor\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Simple invocation - just pass the task\n",
    "response = agent.handle_task(\"I just finished reading the 1984 book, and I loved it.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468086df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO - [TOOL INVOKED] Community recommender triggered with input: Can you provide community recommendations?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CommunityRecommender` with `{'sentence': 'Can you provide community recommendations?'}`\n",
      "responded: {\n",
      "    \"response\": \"I will need to use the CommunityRecommender tool to provide you with book recommendations from the community.\",\n",
      "    \"reason\": \"User requested community recommendations for books.\",\n",
      "    \"used_tool\": \"CommunityRecommender\"\n",
      "}\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[TOOL RESULT]\n",
      "Type: Recommendation:\n",
      "Here are community recommendations for Content Consumption:\n",
      "\\n• Book:\\n  - occasionally reads news articles: liked by 10 users\n",
      "\\n  - reading graphic novels: liked by 5 users\n",
      "\\n  - reading science fiction: liked by 5 users\n",
      "\\n• Game:\\n  - card games: liked by 6 users\n",
      "\\n  - strategy games: liked by 6 users\n",
      "\\n  - arcade games: liked by 5 users\n",
      "\\n• Movie:\\n  - watching animated movies: liked by 6 users\n",
      "\\n  - watching fantasy movies: liked by 6 users\n",
      "\\n  - watching historical dramas: liked by 6 users\n",
      "\\n• Music:\\n  - hip hop music: liked by 6 users\n",
      "\\n  - indie music: liked by 6 users\n",
      "\\n  - reggae music: liked by 6 users\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"response\": \"Here are some book recommendations from the community:\\n- occasionally reads news articles: liked by 10 users\\n- reading graphic novels: liked by 5 users\\n- reading science fiction: liked by 5 users\",\n",
      "    \"reason\": \"Community recommendations for books based on user's request.\",\n",
      "    \"used_tool\": \"CommunityRecommender\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"response\": \"Here are some book recommendations from the community:\\n- occasionally reads news articles: liked by 10 users\\n- reading graphic novels: liked by 5 users\\n- reading science fiction: liked by 5 users\",\n",
      "    \"reason\": \"Community recommendations for books based on user's request.\",\n",
      "    \"used_tool\": \"CommunityRecommender\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = agent.handle_task(\"Give me some book recommendation from the community, then.\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5a0242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"response\": \"You can consider watching 'Inception' or 'The Shawshank Redemption'. Both are highly acclaimed movies that are worth watching.\",\n",
      "    \"reason\": \"General movie recommendation based on popular choices.\",\n",
      "    \"used_tool\": \"None\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"response\": \"You can consider watching 'Inception' or 'The Shawshank Redemption'. Both are highly acclaimed movies that are worth watching.\",\n",
      "    \"reason\": \"General movie recommendation based on popular choices.\",\n",
      "    \"used_tool\": \"None\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Simple invocation - just pass the task\n",
    "response = agent.handle_task(\"So, which movies should I watch tonight?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2ef7e",
   "metadata": {},
   "source": [
    "# Labeling Assistatn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\persoagent_backend\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:808: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  _ = torch.tensor([0], device=i)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07363fea8b34280937b15b2c48a826c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5\n",
      "Reasoning: The user persona shows a strong interest in reading novels, which aligns well with the classification's focus on reading books and literature. However, the user also enjoys other forms of media such as video games, sci-fi movies, and classical music, which are not directly related to the classification's focus on reading. Therefore, while there is a significant overlap, the user's diverse interests prevent a perfect score.\n"
     ]
    }
   ],
   "source": [
    "# Set memory limits before importing transformers\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import re\n",
    "\n",
    "class LabelingAssistant:\n",
    "    def __init__(self):\n",
    "        # Use 75% of GPU memory (9GB out of 12GB)\n",
    "        torch.cuda.set_per_process_memory_fraction(0.75)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"./Tokenizers/Phi-4-mini-instruct\")\n",
    "        \n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"./LLMs/Phi-4-mini-instruct\", \n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "    \n",
    "    def get_alignment_score(self, user_persona: str, classification_description: str) -> dict:\n",
    "        prompt = f\"\"\"<|user|>\n",
    "Analyze alignment between user persona and classification. Return JSON with score (0.0-1.0) and reasoning.\n",
    "\n",
    "User Persona: {user_persona}\n",
    "Classification: {classification_description}\n",
    "\n",
    "Response format: {{\"score\": 0.85, \"reasoning\": \"explanation\"}}\n",
    "<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=100,\n",
    "                temperature=0.3,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                use_cache=False\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        \n",
    "        del outputs, inputs\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        try:\n",
    "            json_match = re.search(r'\\{[^}]*\"score\"[^}]*\\}', response)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        score_match = re.search(r'([0-9.]+)', response)\n",
    "        score = float(score_match.group(1)) if score_match else 0.5\n",
    "        return {\"score\": min(1.0, score), \"reasoning\": response.strip()}\n",
    "    \n",
    "    def reset_memory(self):\n",
    "        torch.cuda.set_per_process_memory_fraction(1.0)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Usage\n",
    "assistant = LabelingAssistant()\n",
    "\n",
    "user_persona = \"Content Consumption: | Book: likes reading novels | Game: plays video games | Movie: likes watching sci-fi | Music: likes classical music\"\n",
    "classification = \"Classify users based on their passion for reading books and literature.\"\n",
    "\n",
    "result = assistant.get_alignment_score(user_persona, classification)\n",
    "print(f\"Score: {result['score']}\")\n",
    "print(f\"Reasoning: {result['reasoning']}\")\n",
    "\n",
    "assistant.reset_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c51979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Add console handler\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73df343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - SQLitePersonaDB initialized\n",
      "INFO - Found 5 candidate users for classification task 'Content Consumption'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['user_36', 'user_19', 'user_02', 'user_06', 'user_34']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.persona_util import SQLitePersonaDB\n",
    "\n",
    "db = SQLitePersonaDB()\n",
    "\n",
    "res = db.get_random_candidate_usernames(classification_task_name=\"Content Consumption\", count=5)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe0f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\persoagent_backend\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:808: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  _ = torch.tensor([0], device=i)\n",
      "INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd3f5f9a8af45fa9a4c1d2eba3b76af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - SQLitePersonaDB initialized\n",
      "INFO - Found 5 candidate users for classification task 'Camping Enthusiast'\n",
      "INFO - Found 5 candidates for task 'Camping Enthusiast'\n",
      "INFO - Persona Summary for user_31: \n",
      "User user_31 preferences: || Career Development - Career: prefers_path academia | Education: studied_at Columbia | Skill: has_skill writing || Content Consumption - Book: likes reading mysteries | Game: plays role-playing games | Movie: likes watching adventure movies | Music: likes blues music || Lifestyle Optimization - Exercise: has_hobby climbing | Mental Health: focuses_on reading self-help | Outdoor: likes hiking and sleeping in tents\n",
      "INFO - Persona Summary for user_13: \n",
      "User user_13 preferences: || Career Development - Career: prefers_path industry | Education: studied_at Yale | Skill: has_skill teaching || Content Consumption - Book: likes reading philosophy | Game: plays arcade games | Movie: likes watching fantasy movies | Music: likes indie music || Lifestyle Optimization - Exercise: has_hobby pilates | Mental Health: focuses_on group therapy | Outdoor: has_experience_with campfire cooking\n",
      "INFO - Persona Summary for user_30: \n",
      "User user_30 preferences: || Career Development - Career: prefers_path industry | Education: studied_at UCLA | Skill: has_skill software development || Content Consumption - Book: likes reading history | Game: plays simulation games | Movie: likes watching animated movies | Music: likes hip hop music || Lifestyle Optimization - Exercise: has_hobby skating | Mental Health: focuses_on positive affirmations\n",
      "INFO - Persona Summary for user_12: \n",
      "User user_12 preferences: || Career Development - Career: prefers_path academia | Education: studied_at Yale | Skill: has_skill teaching || Content Consumption - Book: likes reading cookbooks | Game: plays strategy games | Movie: likes watching fantasy movies | Music: likes indie music || Lifestyle Optimization - Exercise: has_hobby pilates | Mental Health: focuses_on group therapy\n",
      "INFO - Persona Summary for user_37: \n",
      "User user_37 preferences: || Career Development - Career: prefers_path industry | Education: studied_at Princeton | Skill: has_skill networking || Content Consumption - Book: likes reading mysteries | Game: plays role-playing games | Movie: likes watching romance movies | Music: likes country music || Lifestyle Optimization - Exercise: has_hobby mountain biking | Mental Health: focuses_on breathing exercises | Outdoor: has_experience_with campfire cooking\n",
      "INFO - GPU memory released\n"
     ]
    }
   ],
   "source": [
    "from src.tools.labeling_assistant import LabelingAssistant\n",
    "\n",
    "assistant = LabelingAssistant()\n",
    "pool_size = 5\n",
    "clf_task_name = \"Camping Enthusiast\"\n",
    "result = assistant.get_alignment_score(pool_size, clf_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43da079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'username': 'user_32',\n",
       "  'full_name': 'Indigo Underwood',\n",
       "  'age': 39,\n",
       "  'gender': 'female',\n",
       "  'score': 0.85,\n",
       "  'reasoning': '```json\\n{\\n  \"score\": 0.85,\\n  \"reasoning\": \"User has a hobby in camping, indicating a strong interest in outdoor activities, which aligns well with the classification criteria.\"\\n}\\n``` <|end|>'},\n",
       " {'username': 'user_39',\n",
       "  'full_name': 'Finley Nash',\n",
       "  'age': 23,\n",
       "  'gender': 'male',\n",
       "  'score': 0.0,\n",
       "  'reasoning': '```json\\n{\\n  \"score\": 0.0,\\n  \"reasoning\": \"No topics in the user persona relate to camping and outdoor activities.\"\\n}\\n``` <|end|>'},\n",
       " {'username': 'user_08',\n",
       "  'full_name': 'Hannah Adams',\n",
       "  'age': 24,\n",
       "  'gender': 'female',\n",
       "  'score': 0.7,\n",
       "  'reasoning': '```json\\n{\\n  \"score\": 0.7,\\n  \"reasoning\": \"User has a hobby in mountain biking, which is related to outdoor activities. However, no direct interest in camping or broader outdoor activities is mentioned.\"\\n}\\n``` <|end|>'},\n",
       " {'username': 'user_20',\n",
       "  'full_name': 'Quinn Vega',\n",
       "  'age': 19,\n",
       "  'gender': 'female',\n",
       "  'score': 0.0,\n",
       "  'reasoning': '```json\\n{\\n  \"score\": 0.0,\\n  \"reasoning\": \"No topics in the user persona relate to camping and outdoor activities.\"\\n}\\n``` <|end|>'},\n",
       " {'username': 'user_36',\n",
       "  'full_name': 'Jules Keller',\n",
       "  'age': 25,\n",
       "  'gender': 'female',\n",
       "  'score': 0.6,\n",
       "  'reasoning': '```json\\n{\\n  \"score\": 0.6,\\n  \"reasoning\": \"User has a hobby in outdoor adventures, which is related to camping and outdoor activities, indicating moderate alignment.\"\\n}\\n``` <|end|>'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfaabc",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee436faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:persona_util:SQLitePersonaDB initialized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "from utils.persona_util import SQLitePersonaDB\n",
    "\n",
    "db = SQLitePersonaDB()\n",
    "db._create_tables()\n",
    "pred = db.get_predictions(classification_task_id= 2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb56c51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:persona_util:SQLitePersonaDB initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Task: Camping Enthusiast\n",
      "\n",
      "User 1: user_27\n",
      "Filtered:  | prefers_path academia | studied_at Oxford | has_skill marketing | likes reading children's books | plays mobile games | likes watching thrillers | likes jazz music | has_hobby hiking | focuses_on journaling | frequently_visits national parks\n",
      "\n",
      "User 2: user_38\n",
      "Filtered:  | prefers_path industry | studied_at Oxford | has_skill marketing | likes reading biographies | plays arcade games | likes watching thrillers | likes jazz music | has_hobby hiking | focuses_on journaling | has_experience_with campfire cooking\n"
     ]
    }
   ],
   "source": [
    "# Simple test for classification functions\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from utils.persona_util import SQLitePersonaDB\n",
    "\n",
    "db = SQLitePersonaDB()\n",
    "\n",
    "# Get classification task name\n",
    "task_info = db.get_classification_task(2)\n",
    "print(f\"Classification Task: {task_info['name']}\")\n",
    "\n",
    "# Get two users from responses\n",
    "responses = db.get_classification_task_responses(task_info['name'])\n",
    "user1 = responses[0]['username']\n",
    "user2 = responses[1]['username']\n",
    "\n",
    "print(f\"\\nUser 1: {user1}\")\n",
    "summary1 = db.get_user_persona_summary(user1)\n",
    "filtered1 = db.filter_persona_summary_from_topics(summary1)\n",
    "print(f\"Filtered: {filtered1}\")\n",
    "\n",
    "print(f\"\\nUser 2: {user2}\")\n",
    "summary2 = db.get_user_persona_summary(user2)\n",
    "filtered2 = db.filter_persona_summary_from_topics(summary2)\n",
    "print(f\"Filtered: {filtered2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e5c0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:persona_util:SQLitePersonaDB initialized\n",
      "INFO:persona_util:Found 10 candidate users for classification task 'Camping Enthusiast'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Task: Camping Enthusiast\n",
      "Training result: {'success': True, 'training_size': 12, 'accepted': 6, 'declined': 6}\n",
      "\n",
      "Predictions:\n",
      "  user_33: declined (confidence: 0.231)\n",
      "  user_16: accepted (confidence: 0.095)\n",
      "  user_39: declined (confidence: 0.076)\n",
      "  user_02: accepted (confidence: 0.042)\n",
      "  user_01: accepted (confidence: 0.023)\n"
     ]
    }
   ],
   "source": [
    "# Test PersonaClassifier\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from tools.persona_classifier import PersonaClassifier\n",
    "\n",
    "classifier = PersonaClassifier()\n",
    "\n",
    "# Get classification task name from ID 2\n",
    "task_info = classifier.db.get_classification_task(2)\n",
    "task_name = task_info['name']\n",
    "print(f\"Classification Task: {task_name}\")\n",
    "\n",
    "# Train classifier\n",
    "result = classifier.train(task_name)\n",
    "print(f\"Training result: {result}\")\n",
    "\n",
    "if result.get(\"success\"):\n",
    "    # Get candidates and predict\n",
    "    candidates = classifier.db.get_random_candidate_usernames(task_name, 10)\n",
    "    if candidates:\n",
    "        predictions = classifier.predict(candidates, 5)\n",
    "        print(f\"\\nPredictions:\")\n",
    "        for pred in predictions:\n",
    "            print(f\"  {pred['username']}: {pred['prediction']} (confidence: {pred['confidence']})\")\n",
    "    else:\n",
    "        print(\"No candidates found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "644cc5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:persona_util:SQLitePersonaDB initialized\n",
      "INFO:persona_util:Found 30 candidate users for classification task 'Camping Enthusiast'\n",
      "INFO:persona_util:Saved 8 predictions for classification task 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification_task': {'id': 2, 'name': 'Camping Enthusiast'}, 'predictions': [{'username': 'user_22', 'predicted_label': 'Camping Enthusiast', 'confidence': np.float64(0.637)}, {'username': 'user_10', 'predicted_label': 'Camping Enthusiast', 'confidence': np.float64(0.667)}, {'username': 'user_25', 'predicted_label': 'Camping Enthusiast', 'confidence': np.float64(0.64)}, {'username': 'user_08', 'predicted_label': 'Camping Enthusiast', 'confidence': np.float64(0.649)}, {'username': 'user_12', 'predicted_label': 'Not Enthusiast', 'confidence': np.float64(0.63)}, {'username': 'user_36', 'predicted_label': 'Not Enthusiast', 'confidence': np.float64(0.709)}, {'username': 'user_33', 'predicted_label': 'Not Enthusiast', 'confidence': np.float64(0.663)}, {'username': 'user_40', 'predicted_label': 'Not Enthusiast', 'confidence': np.float64(0.602)}]}\n"
     ]
    }
   ],
   "source": [
    "# Test updated classifier\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from tools.persona_classifier import PersonaClassifier\n",
    "\n",
    "classifier = PersonaClassifier()\n",
    "\n",
    "# Train and predict\n",
    "classification_task_id = 2\n",
    "task_info = classifier.db.get_classification_task(classification_task_id)\n",
    "result = classifier.train(task_info['name'])\n",
    "\n",
    "if result.get(\"success\"):\n",
    "    predictions = classifier.predict_and_save(classification_task_id, count=30, min_confidence=0.6)\n",
    "    print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34a5dcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification_task': {'id': 2, 'name': 'Camping Enthusiast'},\n",
       " 'predictions': [{'username': 'user_22',\n",
       "   'predicted_label': 'Camping Enthusiast',\n",
       "   'confidence': np.float64(0.637)},\n",
       "  {'username': 'user_10',\n",
       "   'predicted_label': 'Camping Enthusiast',\n",
       "   'confidence': np.float64(0.667)},\n",
       "  {'username': 'user_25',\n",
       "   'predicted_label': 'Camping Enthusiast',\n",
       "   'confidence': np.float64(0.64)},\n",
       "  {'username': 'user_08',\n",
       "   'predicted_label': 'Camping Enthusiast',\n",
       "   'confidence': np.float64(0.649)},\n",
       "  {'username': 'user_12',\n",
       "   'predicted_label': 'Not Enthusiast',\n",
       "   'confidence': np.float64(0.63)},\n",
       "  {'username': 'user_36',\n",
       "   'predicted_label': 'Not Enthusiast',\n",
       "   'confidence': np.float64(0.709)},\n",
       "  {'username': 'user_33',\n",
       "   'predicted_label': 'Not Enthusiast',\n",
       "   'confidence': np.float64(0.663)},\n",
       "  {'username': 'user_40',\n",
       "   'predicted_label': 'Not Enthusiast',\n",
       "   'confidence': np.float64(0.602)}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b400846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
